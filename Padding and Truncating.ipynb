{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638eb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tokenizer and pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3572080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My favorite food is ice cream', 'do you like ice cream too?', 'My dog likes ice cream!', 'your favorite flavor of icecream is chocolate', \"chocolate isn't good for dogs\", 'your dog, your cat, and your parrot prefer broccoli']\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    'My favorite food is ice cream',\n",
    "    'do you like ice cream too?',\n",
    "    'My dog likes ice cream!',\n",
    "    \"your favorite flavor of icecream is chocolate\",\n",
    "    \"chocolate isn't good for dogs\",\n",
    "    \"your dog, your cat, and your parrot prefer broccoli\"\n",
    "]\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea2093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b9221c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, 'your': 2, 'ice': 3, 'cream': 4, 'my': 5, 'favorite': 6, 'is': 7, 'dog': 8, 'chocolate': 9, 'food': 10, 'do': 11, 'you': 12, 'like': 13, 'too': 14, 'likes': 15, 'flavor': 16, 'of': 17, 'icecream': 18, \"isn't\": 19, 'good': 20, 'for': 21, 'dogs': 22, 'cat': 23, 'and': 24, 'parrot': 25, 'prefer': 26, 'broccoli': 27}\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d9082e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 6, 10, 7, 3, 4], [11, 12, 13, 3, 4, 14], [5, 8, 15, 3, 4], [2, 6, 16, 17, 18, 7, 9], [9, 19, 20, 21, 22], [2, 8, 2, 23, 24, 2, 25, 26, 27]]\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "print (sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca64c6b",
   "metadata": {},
   "source": [
    "Make the sequences all the same length\n",
    "Later, when you feed the sequences into a neural network to train a model, the sequences all need to be uniform in size. Currently the sequences have varied lengths, so the next step is to make them all be the same size, either by padding them with zeros and/or truncating them.\n",
    "\n",
    "Use f.keras.preprocessing.sequence.pad_sequences to add zeros to the sequences to make them all be the same length. By default, the padding goes at the start of the sequences, but you can specify to pad at the end.\n",
    "\n",
    "You can optionally specify the maximum length to pad the sequences to. Sequences that are longer than the specified max length will be truncated. By default, sequences are truncated from the beginning of the sequence, but you can specify to truncate from the end.\n",
    "\n",
    "If you don't provide the max length, then the sequences are padded to match the length of the longest sentence.\n",
    "\n",
    "For all the options when padding and truncating sequences, see https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac878da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Index =  {'<OOV>': 1, 'your': 2, 'ice': 3, 'cream': 4, 'my': 5, 'favorite': 6, 'is': 7, 'dog': 8, 'chocolate': 9, 'food': 10, 'do': 11, 'you': 12, 'like': 13, 'too': 14, 'likes': 15, 'flavor': 16, 'of': 17, 'icecream': 18, \"isn't\": 19, 'good': 20, 'for': 21, 'dogs': 22, 'cat': 23, 'and': 24, 'parrot': 25, 'prefer': 26, 'broccoli': 27}\n",
      "\n",
      "Sequences =  [[5, 6, 10, 7, 3, 4], [11, 12, 13, 3, 4, 14], [5, 8, 15, 3, 4], [2, 6, 16, 17, 18, 7, 9], [9, 19, 20, 21, 22], [2, 8, 2, 23, 24, 2, 25, 26, 27]]\n",
      "\n",
      "Padded Sequences:\n",
      "[[ 0  0  0  5  6 10  7  3  4]\n",
      " [ 0  0  0 11 12 13  3  4 14]\n",
      " [ 0  0  0  0  5  8 15  3  4]\n",
      " [ 0  0  2  6 16 17 18  7  9]\n",
      " [ 0  0  0  0  9 19 20 21 22]\n",
      " [ 2  8  2 23 24  2 25 26 27]]\n"
     ]
    }
   ],
   "source": [
    "padded = pad_sequences(sequences)\n",
    "print(\"\\nWord Index = \" , word_index)\n",
    "print(\"\\nSequences = \" , sequences)\n",
    "print(\"\\nPadded Sequences:\")\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a50fa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  5  6 10  7  3  4]\n",
      " [ 0  0  0  0  0  0  0  0  0 11 12 13  3  4 14]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  5  8 15  3  4]\n",
      " [ 0  0  0  0  0  0  0  0  2  6 16 17 18  7  9]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  9 19 20 21 22]\n",
      " [ 0  0  0  0  0  0  2  8  2 23 24  2 25 26 27]]\n"
     ]
    }
   ],
   "source": [
    "# Specify a max length for the padded sequences\n",
    "padded = pad_sequences(sequences, maxlen=15)\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55398346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  6 10  7  3  4  0  0  0  0  0  0  0  0  0]\n",
      " [11 12 13  3  4 14  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  8 15  3  4  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  6 16 17 18  7  9  0  0  0  0  0  0  0  0]\n",
      " [ 9 19 20 21 22  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  8  2 23 24  2 25 26 27  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Put the padding at the end of the sequences\n",
    "padded = pad_sequences(sequences, maxlen=15, padding=\"post\")\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "348af476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  3  4]\n",
      " [ 3  4 14]\n",
      " [15  3  4]\n",
      " [18  7  9]\n",
      " [20 21 22]\n",
      " [25 26 27]]\n"
     ]
    }
   ],
   "source": [
    "# Limit the length of the sequences, you will see some sequences get truncated\n",
    "padded = pad_sequences(sequences, maxlen=3)\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33eede80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"my best friend's favorite ice cream flavor is strawberry\", \"my dog's best friend is a manatee\"]\n",
      "<OOV> has the number 1 in the word index.\n",
      "\n",
      "Test Sequence =  [[5, 1, 1, 6, 3, 4, 16, 7, 1], [5, 1, 1, 1, 7, 1, 1]]\n",
      "\n",
      "Padded Test Sequence: \n",
      "[[ 0  5  1  1  6  3  4 16  7  1]\n",
      " [ 0  0  0  5  1  1  1  7  1  1]]\n"
     ]
    }
   ],
   "source": [
    "# Try turning sentences that contain words that \n",
    "# aren't in the word index into sequences.\n",
    "# Add your own sentences to the test_data\n",
    "test_data = [\n",
    "    \"my best friend's favorite ice cream flavor is strawberry\",\n",
    "    \"my dog's best friend is a manatee\"\n",
    "]\n",
    "print (test_data)\n",
    "\n",
    "# Remind ourselves which number corresponds to the\n",
    "# out of vocabulary token in the word index\n",
    "print(\"<OOV> has the number\", word_index['<OOV>'], \"in the word index.\")\n",
    "\n",
    "# Convert the test sentences to sequences\n",
    "test_seq = tokenizer.texts_to_sequences(test_data)\n",
    "print(\"\\nTest Sequence = \", test_seq)\n",
    "\n",
    "# Pad the new sequences\n",
    "padded = pad_sequences(test_seq, maxlen=10)\n",
    "print(\"\\nPadded Test Sequence: \")\n",
    "\n",
    "# Notice that \"1\" appears in the sequence wherever there's a word \n",
    "# that's not in the word index\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd805c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a786c9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bdfe51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
